{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Niklas Goes BERT\n","---------------\n","``` \n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-10T09:46:49.473550Z","iopub.status.busy":"2024-02-10T09:46:49.472712Z","iopub.status.idle":"2024-02-10T09:46:49.481651Z","shell.execute_reply":"2024-02-10T09:46:49.480735Z","shell.execute_reply.started":"2024-02-10T09:46:49.473516Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/niklashahn/anaconda3/envs/Masterarbeit_Speeches/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["2.2.0\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/niklashahn/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["#import modules\n","import numpy as np \n","import pandas as pd \n","import random\n","import time\n","import csv\n","import nltk\n","import pickle\n","import time\n","import gc\n","import os\n","import torch\n","from datasets import Dataset\n","from tqdm.auto import tqdm\n","nltk.download('punkt')\n","\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["Wrangling"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T09:47:00.069995Z","iopub.status.busy":"2024-02-10T09:47:00.069089Z","iopub.status.idle":"2024-02-10T09:47:08.566132Z","shell.execute_reply":"2024-02-10T09:47:08.565210Z","shell.execute_reply.started":"2024-02-10T09:47:00.069960Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/niklashahn/anaconda3/envs/Masterarbeit_Speeches/lib/python3.11/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if _pandas_api.is_sparse(col):\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['description', 'newspaper', 'id'],\n","    num_rows: 100\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["spgl_dat = pd.read_csv(\"/Users/niklashahn/Library/CloudStorage/Dropbox/Masterarbeit/Daten_Analyse/_data/_processed/sample_classification/sampling_data_media.csv\")\n","#spgl_dat = spgl_dat.dropna(subset=['description'])\n","spgl_dat = spgl_dat.dropna(subset=['description'])\n","\n","hg_data = Dataset.from_pandas(spgl_dat)\n","hg_data\n","#dataset = hg_data.map(tokenize_dataset, batched=True, remove_columns=hg_data.column_names)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T09:12:10.979528Z","iopub.status.busy":"2024-02-10T09:12:10.979191Z","iopub.status.idle":"2024-02-10T09:12:10.989858Z","shell.execute_reply":"2024-02-10T09:12:10.988783Z","shell.execute_reply.started":"2024-02-10T09:12:10.979502Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Bruce Lee machte das Martial-Arts-Kino aus Hongkong weltberühmt. Nun will der oscarprämierte Regisseur Ang Lee das Leben dieses »brillanten« Mannes verfilmen – mit seinem Sohn in der Hauptrolle.'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["spgl_dat[\"description\"][118766]# desc = haedline"]},{"cell_type":"markdown","metadata":{},"source":["Loading BERT\n","--------------------\n"]},{"cell_type":"markdown","metadata":{},"source":["model"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T09:37:51.560508Z","iopub.status.busy":"2024-02-10T09:37:51.560173Z","iopub.status.idle":"2024-02-10T09:38:28.211320Z","shell.execute_reply":"2024-02-10T09:38:28.210505Z","shell.execute_reply.started":"2024-02-10T09:37:51.560482Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at poltextlab/xlm-roberta-large-german-media-cap-v3 and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([21, 1024]) in the checkpoint and torch.Size([22, 1024]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([21]) in the checkpoint and torch.Size([22]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import (AutoModelForSequenceClassification, AutoTokenizer, \n","                          Trainer, TrainingArguments)\n","\n","CAP_NUM_DICT = {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', \n","6: '7', 7: '8', 8: '9', 9: '10', 10: '12', 11: '13', 12: '14', \n","13: '15', 14: '16', 15: '17', 16: '18', 17: '19', 18: '20', 19: \n","'21', 20: '23', 21: '999'}\n","num_labels = len(CAP_NUM_DICT)\n","\n","\n","model = AutoModelForSequenceClassification.from_pretrained('poltextlab/xlm-roberta-large-german-media-cap-v3',\n","                                                           num_labels=num_labels,\n","                                                           problem_type=\"multi_label_classification\",\n","                                                           ignore_mismatched_sizes=True\n","                                                           )\n","device = torch.device(\"mps\")\n","model.to(\"mps\")\n","\n","#training_args = TrainingArguments(\n","#    output_dir=\".\",\n","#    logging_strategy='epoch',\n","#    num_train_epochs=10,\n","#    per_device_train_batch_size=8,\n","#    per_device_eval_batch_size=8,\n","#    learning_rate=5e-06,\n","#    seed=42,\n","#    save_strategy='epoch',\n","#    evaluation_strategy='epoch',\n","#    save_total_limit=1,\n","#    load_best_model_at_end=True\n","#)\n","\n","training_args = TrainingArguments(\n","    output_dir='.',\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Tokenize"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T09:47:46.761711Z","iopub.status.busy":"2024-02-10T09:47:46.761341Z","iopub.status.idle":"2024-02-10T09:48:09.871750Z","shell.execute_reply":"2024-02-10T09:48:09.870618Z","shell.execute_reply.started":"2024-02-10T09:47:46.761682Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                   \r"]}],"source":["tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')\n","\n","def tokenize_dataset(data : pd.DataFrame):\n","    #tokenized = tokenizer(data[\"description\"],\n","    tokenized = tokenizer(data[\"description\"],\n","                          max_length=128,\n","                          truncation=True,\n","                          padding=\"max_length\")\n","    return tokenized\n","\n","\n","dataset = hg_data.map(tokenize_dataset, batched=True, remove_columns=hg_data.column_names)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T09:44:03.621122Z","iopub.status.busy":"2024-02-10T09:44:03.620781Z","iopub.status.idle":"2024-02-10T09:44:03.626255Z","shell.execute_reply":"2024-02-10T09:44:03.625131Z","shell.execute_reply.started":"2024-02-10T09:44:03.621096Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n"]}],"source":["first_item = dataset[0]\n","\n","# Print the keys\n","print(dir(first_item))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-10T09:48:14.519774Z","iopub.status.busy":"2024-02-10T09:48:14.519417Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:01<00:00,  6.66it/s]\n"]}],"source":["probs = trainer.predict(test_dataset=dataset).predictions\n","predicted = pd.DataFrame(np.argmax(probs, axis=1)).replace({0: CAP_NUM_DICT}).rename(\n","    columns={0: 'predicted'}).reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["spgl_dat_class = pd.concat([spgl_dat, predicted], axis=1)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                         description newspaper  id predicted\n","0  Hier finden Sie Informationen zu dem Thema „Kr...      zeit   1         5\n","1  Hier finden Sie Informationen zu dem Thema „Ge...      zeit   2        14\n","2  Im März kritisierte Lise Klaveness Katar auf o...   spiegel   3         4\n","3  Adler-Antrag auf Insolvenz in Eigenverwaltung ...      welt   4         4\n","4  Germany has made massive changes to foreign an...   spiegel   5         5\n"]}],"source":["print(spgl_dat_class.head())\n","spgl_dat_class.to_csv('_data/_processed/sample_classification/bert_media.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Old BERT Stuff For Reference - Likely Unncessary"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocess Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_name = 'bert-base-uncased'\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","\n","def preproc_df(dataframe):\n","\n","    test_content = tokenizer(dataframe['tweet'].tolist(), padding= \"max_length\" , truncation=True, return_tensors=\"pt\")\n","    test_labels = dataframe['label'].map({\"sexist\": 1, \"non-sexist\": 0}).tolist()\n","\n","    # Assuming 'test_df' is your DataFrame with 'text' column for test tweets and 'label' column for test labels\n","    # Preprocess data (tokenize, encode) and convert labels to numerical form if needed\n","\n","    # Tokenize input text for test data\n","    class TweetDataset(Dataset):\n","        def __init__(self, encodings, labels):\n","            self.encodings = encodings\n","            self.labels = labels\n","\n","        def __getitem__(self, idx):\n","            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","            item['labels'] = torch.tensor(self.labels[idx])\n","            return item\n","\n","        def __len__(self):\n","            return len(self.labels)\n","\n","    # Create a test dataset\n","    test_dataset = TweetDataset(test_content, test_labels)  # Assuming TweetDataset is similar to the one used in training\n","\n","    # Create a DataLoader for test data\n","    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","    return test_loader"]},{"cell_type":"markdown","metadata":{},"source":["As for part 1.1., the models are tested on the whole dataset and the individual datasets"]},{"cell_type":"markdown","metadata":{},"source":["### Test Function"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    predictions = []\n","    true_labels = []\n","    \n","    \n","    device = torch.device(\"cuda\")\n","    model.to(\"cuda\")\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            _, predicted = torch.max(logits, 1)\n","\n","            predictions.extend(predicted.cpu().numpy())\n","            true_labels.extend(labels.cpu().numpy())\n","\n","    accuracy = accuracy_score(true_labels, predictions)\n","    precision = precision_score(true_labels, predictions)\n","    recall = recall_score(true_labels, predictions)\n","    f1 = f1_score(true_labels, predictions)\n","    confusion = confusion_matrix(true_labels, predictions)\n","\n","    #print(f\"Accuracy: {accuracy:.4f}\")\n","    #print(f\"Precision: {precision:.4f}\")\n","    #print(f\"Recall: {recall:.4f}\")\n","    #print(f\"F1-score: {f1:.4f}\")\n","    #print(\"Confusion Matrix:\")\n","    #print(confusion)\n","    \n","    return f1\n","\n","# Usage:\n","# Assuming you have a test_loader for your test data (similar to the train_loader used during training)\n","# Call evaluate_model function after training to evaluate the model's performance\n","# For example:\n","# evaluate_model(model, test_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["f1_macro = evaluate_model(bert_m1, bert_test_ood1)\n","f1_macro"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["f1_scores_bert = []\n","datasets = [\"ood1\", \"ood2\", \"ood3\", \"hc\", \"full\"]\n","models = [\"m1\", \"m2\", \"m3_gpt\", \"m3_flan\", \"m4_gpt\", \"m4_flan\"]\n","\n","for model in models:\n","    current_model = load_bert_model(f\"/kaggle/input/bert-outputs/bert_outputs/{model}\")\n","        \n","    for df in datasets:\n","        df_name = f\"bert_test_{df}\"\n","        current_df = globals()[df_name]  \n","        \n","        f1_macro = evaluate_model(current_model, current_df)\n","        f1_scores_bert.append(f1_macro)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["f1_scores_bert"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_array = [f1_scores_bert[i:i+5] for i in range(0, len(f1_scores_bert), 5)]\n","f1_scores_bert_df = pd.DataFrame(data_array, columns=[\"ood1\", \"ood2\", \"ood3\", \"hc\", \"full\"], index=[\"og\",  \"mcad\", \"acad_gpt\", \"acad_flan\", \"aex_gpt\", \"aex_flan\"])\n","\n","print(f1_scores_bert_df)\n","\n","f1_scores_bert_df.to_csv(f\"f1_scores_bert_df.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["f1_scores_bert_df = pd.read_csv('/kaggle/input/outputs-all/f1_scores_bert_df.csv')\n","f1_scores_bert_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["f1_scores_svm_df.to_csv(f\"f1_scores_svm_df.csv\", index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["I write my own Bert Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')\n","num_labels = len(CAP_NUM_DICT)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4423754,"sourceId":7599487,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
